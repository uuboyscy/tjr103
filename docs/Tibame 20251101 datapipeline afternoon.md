# Data Pipeline 課堂筆記（2025/11/01 下午）

## 課程焦點

-   延續上午的 GCP 基礎，示範如何把資料管線專案部署到雲端 VM。
-   以 Airflow 為案例，梳理從開發、版控到部署與驗證的整體流程。
-   強調團隊協作時的分支管理、程式碼集中於 GitHub 以及雲端主機的角色定位。

------------------------------------------------------------------------

## 部署流程概觀

-   開發階段在個人電腦完成程式、提交至共用 Repo，透過 Pull Request 確保程式品質。
-   Main 分支視為可部署的來源，由雲端主機（Compute Engine）定期拉取最新內容。
-   雲端主機需要具備 Docker、Git、必要的憑證與目錄權限，才能啟動 Airflow 與掛載專案檔案。
-   若要提升自動化程度，可額外撰寫 Shell Script 或使用 CI/CD 讓部署流程自動化。

------------------------------------------------------------------------

## Compute Engine 與環境佈建

-   建議將常用的 SSH 公鑰登錄在 Project Metadata → SSH Keys，讓後續建立的 VM 自動載入同一組金鑰。
-   建立 VM 時選擇合適的 Series／Machine Type，區分 Standard（不中斷）與 Spot（成本低但可能被回收）使用情境。
-   開機後立即更新套件、安裝 Docker、建立專案目錄並調整檔案權限，以確保容器內外的使用者都能存取。
-   透過 `git clone` 將 Airflow 專案抓到 VM，必要時調整 `core.filemode` 避免因權限變動造成 Git 警告。

------------------------------------------------------------------------

## Airflow 服務配置

-   進入專案目錄後執行 `docker run` 啟動 Airflow，掛載 `dags`、`logs`、`utils`、`tasks` 等目錄，並設定 `PYTHONPATH`。
-   初次啟動後以 `docker exec` 建立預設的 Admin 使用者，確保同學能登入網頁介面操作。
-   若需要修改 DAG，直接在 VM 上更新 Git Repo 或重新拉取最新版本，再重新整理 Airflow UI。
-   提醒同學留意容器內外的路徑對應，避免因權限或路徑錯誤導致 DAG 無法讀取。

------------------------------------------------------------------------

## 防火牆與存取測試

-   新增自訂防火牆規則開放 TCP 8080（或 Airflow UI 使用的埠號），來源可先限定個人 IP 以降低外部風險。
-   防火牆未開放時，瀏覽器即便輸入 `http://<external-ip>:8080` 也無法顯示 Airflow UI，課堂示範了開關差異。
-   覆蓋原有規則或刪除後務必重新整理主機清單確認狀態，避免誤以為服務故障。

------------------------------------------------------------------------

## 維運提醒

-   建議為常見的初始化流程撰寫腳本，減少手動操作造成的遺漏；正式專案甚至會使用 IaC 或 CI/CD 工具。
-   Airflow 佈建完成後應定期檢查 Docker Container 狀態與日誌，確保 Scheduler、Webserver 運作正常。
-   練習將 VM 上的部署步驟紀錄於 README 或筆記，方便未來搬遷環境或協助新成員上手。

------------------------------------------------------------------------

## 參考來源

-   原始逐字稿：tmp/Tibame 20251101 datapipeline afternoon.txt

