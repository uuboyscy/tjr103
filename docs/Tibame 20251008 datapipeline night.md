
# Data Pipeline 課堂筆記（2025/10/08 夜間）

## Parquet 與 CSV 的差異與下載建議

-   比較 CSV（約 1.19 GB）與 Parquet（約 295 MB）的檔案大小與載入速度，建議實務上優先取得 Parquet。
-   強調兩種格式資料內容相同，Parquet 透過壓縮與欄位型別 metadata 讓 Pandas 讀取、搜尋效率更佳。
-   Parquet 可保存欄位型別、partition 訊息等描述性資料，對後續查詢與維運更友善。

------------------------------------------------------------------------

## 資料清理流程複習

-   回顧早上撰寫的 Notebook：從 PDF 整理成 DataFrame、拆分子陣列、保留數值欄位，再進行批次清洗。
-   透過字串切割、正則與型別轉換處理金額、比重等欄位，確保能進行四則運算與統計。
-   重新自頂向下執行整份 Notebook，並改用逗號切割日期時間欄位，避免因空白切割導致時間資訊遺失。

------------------------------------------------------------------------

## 時間欄位與時區處理

-   新增 `datetime` 欄位整合日期與時間，提醒時間資料同樣能做加減、區間過濾等運算。
-   示範面對帶時區的時間欄位時，需先確認原始時區設定，再進行換算或顯示，避免分析結果錯位。
-   使用 `pd.to_datetime` 轉換欄位，並介紹 `errors='coerce'` 等參數處理非法日期，以 NaT 標記待清理資料。

------------------------------------------------------------------------

## 布林篩選與條件組合

-   以 `df[condition]` 練習布林索引，條件寫法類似 SQL 的 where 子句，直接使用比較運算子即可。
-   `&` 與 `|` 對應 SQL 的 AND / OR，複合條件需以括號包覆各子句避免運算優先序問題。
-   補充 `isin`、`between`、字串方法等常用語法，並示範在 Notebook 中快速檢驗條件結果。

------------------------------------------------------------------------

## 分組統計與 MultiIndex

-   透過 `unique` / `nunique` 觀察欄位值，推論資料集為 ETF 組合並判斷關鍵欄位（如 port number、EFF_DT）。
-   使用 `groupby(['port_no', 'eff_dt'])` 搭配 `sum` 等聚合函式檢查各 ETF 權重是否合計為 100%，同時嘗試 `mean`、`std` 等統計。
-   解釋 groupby 回傳 Series 時的 MultiIndex 結構，示範以 `reset_index()`、`agg` 自訂輸出欄位，使結果回復成易於閱讀的 DataFrame。

------------------------------------------------------------------------

## 其他提醒與延伸

-   建議在分析前多觀察資料欄位分布，思考對應的 SQL 與 Pandas 寫法，累積操作直覺。
-   分享職涯建議：大數據專案常用 Java / Scala，熟悉強 OOP 語言能培養嚴謹的程式習慣，Python 則維持快速實作的優勢。

