# Data Pipeline 課堂筆記（2025/10/22 夜間）

## 啟動開發環境

-   課前確認 Docker Desktop 已啟動，透過 `docker ps` 核對 daemon 是否運作。
-   依作業系統（macOS/Linux 或 Windows）執行講師提供的指令啟動 Airflow 相關容器，如有首次拉取影像需等待下載完成。

------------------------------------------------------------------------

## 使用 VS Code Remote Explorer

-   透過 VS Code 左側的 Remote Explorer 連入正在執行的容器，等同於在容器內啟動完整的開發環境。
-   示範在 Remote Explorer 中選擇 Dev Containers 項目，直接將 VS Code 視窗掛載至容器，使檔案總管、終端機都指向容器內部。
-   補充 Remote SSH 擴充功能用途，說明未來可用於連線雲端主機。

------------------------------------------------------------------------

## 導覽 Airflow 專案結構

-   容器中的專案路徑為 `/opt/airflow`，實務開發時需先 `File → Open Folder` 指向該資料夾。
-   說明 `dags/` 為放置 DAG 主程式的唯一位置；`logs/` 由 Airflow 自動產生，不建議手動調整。
-   建議將共用邏輯拆分為 `dags/tasks/`（可視化為 DAG 節點）與 `dags/utils/`（純函數或工具），維持專案可維護性。

------------------------------------------------------------------------

## DAG 與 Task 的思維

-   將完整商業流程視為 DAG，內含多個具體的 Task，各節點可重複組合成不同工作流程。
-   判斷邏輯是否要拆成 Task：若希望在 Airflow UI 中看到獨立節點並追蹤狀態，就應打造 Task；純資料處理小步驟則留在 utils 函式中即可。

------------------------------------------------------------------------

## 其他實務提醒

-   提醒 Apple Silicon 與 Intel 架構環境差異，不建議直接搬移舊機器的系統映像，以免開發工具相容性出問題。
-   若 VS Code 左側資源總管與講師不同，可重新指定開啟資料夾或檢查先前 session 的記錄。
